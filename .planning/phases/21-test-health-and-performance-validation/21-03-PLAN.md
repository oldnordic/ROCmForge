---
phase: 21-test-health-and-performance-validation
plan: 03
type: execute
wave: 2
depends_on: ["21-01", "21-02"]
files_modified:
  - tests/decode_step_integration_tests.rs
  - tests/common/mod.rs
autonomous: true
user_setup: []

must_haves:
  truths:
    - "decode_step_integration_tests run without memory allocation crashes"
    - "GPU fixture is properly initialized before decode_step tests"
    - "Tests gracefully skip when GPU is unavailable"
  artifacts:
    - path: "tests/decode_step_integration_tests.rs"
      provides: "Integration tests for decode_step pipeline"
      min_lines: 200
    - path: "tests/common/mod.rs"
      provides: "GPU_FIXTURE singleton for safe GPU testing"
  key_links:
    - from: "tests/decode_step_integration_tests.rs"
      to: "tests/common/mod.rs"
      via: "GPU_FIXTURE.as_ref()"
      pattern: "GPU_FIXTURE\\.as_ref\\(\\)"
---

<objective>
Fix memory allocation crash in decode_step_integration_tests.

Purpose: The decode_step integration tests crash with memory allocation issues. This is likely due to the GPU_FIXTURE not being used correctly or the backend not being properly initialized. The tests need to use the singleton pattern to avoid multiple GPU initializations.

Output: All decode_step integration tests pass without crashes.
</object>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md

@tests/decode_step_integration_tests.rs
@tests/common/mod.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Fix GPU fixture usage in decode_step tests</name>
  <files>tests/decode_step_integration_tests.rs</files>
  <action>
    The issue: decode_step_integration_tests may be creating multiple backends or not using GPU_FIXTURE correctly, causing memory issues.

    Check the test file (lines 159-244 for test_decode_step_single_layer_cpu_reference). The pattern should be:
    ```rust
    let fixture = GPU_FIXTURE.as_ref()
        .expect("GPU not available - test skipped");
    let backend = fixture.backend();
    ```

    Issues to fix:
    1. Verify all tests use GPU_FIXTURE, not direct HipBackend::new()
    2. Ensure tests have #[serial] attribute to prevent concurrent execution
    3. Check that DeviceTensor::empty uses the shared backend, not creating new allocations
    4. Verify proper error context messages (replace "TODO: add error context" with actual context)

    The STATE.md mentions: "GPU reset crashes were fixed in earlier sessions (GPU_FIXTURE singleton pattern)". Verify the tests follow this pattern.

    Also check: ScratchBufferManager::new parameters. Comments mention "PHASE 24 FIX" for 3rd and 5th params - verify correct parameter order.
  </action>
  <verify>
    cargo test --features rocm --test decode_step_integration_tests 2>&1 | tail -30
  </verify>
  <done>
    All three decode_step integration tests pass:
    - test_decode_step_single_layer_cpu_reference
    - test_decode_step_gpu_matches_cpu_within_tolerance
    - test_decode_step_updates_kv_cache_correctly
  </done>
</task>

</tasks>

<verification>
After task completes:
1. `cargo test --features rocm --test decode_step_integration_tests` runs without SIGSEGV
2. All tests in the file pass
3. GPU memory is properly tracked via GPU_FIXTURE
</verification>

<success_criteria>
- TEST-01: Memory allocation crash in decode_step_integration_tests is fixed
- All decode_step tests pass without crashes
- GPU_FIXTURE singleton pattern is used correctly
</success_criteria>

<output>
After completion, create `.planning/phases/21-test-health-and-performance-validation/21-03-SUMMARY.md`
</output>

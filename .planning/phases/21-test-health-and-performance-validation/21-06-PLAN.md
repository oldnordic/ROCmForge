---
phase: 21-test-health-and-performance-validation
plan: 06
type: execute
wave: 5
depends_on: ["21-05"]
files_modified:
  - tests/sampling_gpu_tests.rs
  - benches/inference_bench.rs
autonomous: false
user_setup: []

must_haves:
  truths:
    - "GPU sampling is faster than CPU fallback (10x+ speedup)"
    - "GPU RoPE eliminates CPU-GPU transfer overhead"
    - "End-to-end inference latency is improved vs v1.1 baseline"
    - "Memory usage is efficient (quantized weights stay on GPU)"
  artifacts:
    - path: "tests/sampling_gpu_tests.rs"
      provides: "GPU sampling performance tests"
    - path: "benches/inference_bench.rs"
      provides: "Inference latency benchmark"
  key_links:
    - from: "Phase 21-06"
      to: "Phase 15 GPU sampling work"
      via: "GPU kernel cache from 15-05"
      pattern: "SamplingKernelCache"
---

<objective>
Validate performance improvements from v1.2 GPU acceleration work.

Purpose: Phases 15-18 implemented GPU kernels for sampling, RoPE, and quantization. This plan validates that those implementations deliver the expected performance improvements over v1.1 CPU fallback.

Output: Performance validation report confirming GPU acceleration benefits.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md

# GPU implementation phases for performance context
@.planning/phases/15-gpu-sampling-kernels/15-06-SUMMARY.md
@.planning/phases/15-gpu-sampling-kernels/15-07-SUMMARY.md
@.planning/phases/16-gpu-rope-implementation/16-01-SUMMARY.md
@.planning/phases/17-gpu-quantization/17-03-SUMMARY.md

@tests/sampling_gpu_tests.rs
@benches/inference_bench.rs
</context>

<tasks>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
    Performance validation tests and benchmarks covering:
    - GPU sampling vs CPU fallback speed comparison
    - GPU RoPE transfer overhead elimination
    - End-to-end inference latency measurement
    - Memory usage efficiency for quantized weights
  </what-built>
  <how-to-verify>
    Run performance validation:

    1. GPU Sampling Performance (PERF-01):
    ```bash
    cargo test --features rocm --test sampling_gpu_tests --release -- --nocapture
    ```
    Look for GPU vs CPU timing comparisons. GPU should be 10x+ faster.

    2. Inference Benchmark (PERF-03):
    ```bash
    cargo bench --features rocm --bench inference_bench 2>&1 | tee benchmark_results.txt
    ```
    Compare against v1.1 baseline if available.

    3. Memory Usage (PERF-04):
    - Verify quantized weights (Q4_0, Q4_K, Q6_K) are loaded via GPU kernels
    - Check that weights remain on GPU (no CPU-GPU round trips during inference)
    - Review Phase 17-03 SUMMARY for fused matmul integration

    4. RoPE Overhead (PERF-02):
    - Review Phase 16-01 SUMMARY for GPU path verification
    - Confirm RoPE is applied on GPU without CPU round-trip

    Create a performance report with:
    - GPU vs CPU timing for sampling operations
    - End-to-end inference latency per token
    - Memory usage observations
    - Comparison to v1.1 baseline (if data available)
  </how-to-verify>
  <resume-signal>
    Type "approved" with performance summary, or describe specific performance issues found.
  </resume-signal>
</task>

</tasks>

<verification>
After checkpoint approval:
1. Performance validation report created in 21-06-SUMMARY.md
2. PERF-01 through PERF-04 requirements validated
3. Performance data documented for future reference
</verification>

<success_criteria>
- PERF-01: GPU sampling is faster than CPU fallback (10x+ speedup)
- PERF-02: GPU RoPE eliminates CPU-GPU transfer overhead
- PERF-03: End-to-end inference latency is improved vs v1.1 baseline
- PERF-04: Memory usage is efficient (quantized weights stay on GPU)
</success_criteria>

<output>
After completion, create `.planning/phases/21-test-health-and-performance-validation/21-06-SUMMARY.md` with performance validation report.
</output>

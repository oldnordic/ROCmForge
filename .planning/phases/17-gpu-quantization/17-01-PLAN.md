---
phase: 17-gpu-quantization
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/ggml/hip_backend/ops/q4_0_dequant.rs
  - src/ggml/hip_backend/ops/mod.rs
  - src/loader/gguf.rs
  - tests/q_dequant_tests.rs
autonomous: true

must_haves:
  truths:
    - "Q4_0 dequantization loads and executes the precompiled HSACO kernel on GPU"
    - "Q4_0 quantized weights are uploaded directly to GPU (no CPU dequantization)"
    - "GPU dequantization produces bit-exact results matching CPU reference"
    - "CPU fallback path still works when GPU kernel is unavailable"
  artifacts:
    - path: "src/ggml/hip_backend/ops/q4_0_dequant.rs"
      provides: "GPU kernel invocation wrapper for Q4_0 dequantization"
      exports: ["dequantize_q4_0_kernel_cached", "get_or_init_q4_0_dequant_cache"]
      min_lines: 100
    - path: "src/loader/gguf.rs"
      provides: "Loader integration point for Q4_0 GPU dequantization"
      contains: "Q4_0_DEQUANT_HSACO"
    - path: "tests/q_dequant_tests.rs"
      provides: "Automated unit tests for GPU quantization kernels"
      contains: "test_gpu_q4_0_bit_exact"
  key_links:
    - from: "src/loader/gguf.rs::load_tensor_to_gpu"
      to: "src/ggml/hip_backend/ops/q4_0_dequant.rs::dequantize_q4_0_kernel_cached"
      via: "Match arm for GgufTensorType::Q4_0 calls GPU dequant wrapper"
      pattern: "GgufTensorType::Q4_0.*=>.*dequantize_q4_0_kernel_cached"
    - from: "src/ggml/hip_backend/ops/q4_0_dequant.rs"
      to: "Q4_0_DEQUANT_HSACO env var"
      via: "Kernel cache loads HSACO file path"
      pattern: 'std::env::var\("Q4_0_DEQUANT_HSACO"\)'
---

<objective>
Implement GPU-side Q4_0 dequantization using existing HIP kernel, replacing CPU fallback in tensor loading path.

Purpose: Enable on-device Q4_0 dequantization to eliminate ~17x memory bandwidth waste from CPU dequant + FP32 upload. The kernel already exists - this is integration work.

Output: Q4_0 weights uploaded as quantized bytes, dequantized on GPU, cached as FP32 DeviceTensor.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@.planning/phases/17-gpu-quantization/17-RESEARCH.md
@.planning/phases/15-gpu-sampling-kernels/15-05-SUMMARY.md

# Source files to reference
@src/ggml/hip_backend/ops/q4_0_dequant.rs
@src/ggml/hip_backend/ops/quantized_matmul.rs
@src/loader/gguf.rs
@kernels/q4_0_dequant.hip
@src/attention/kernels.rs
@tests/q_dequant_tests.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement Q4_0 GPU kernel cache and wrapper function</name>
  <files>src/ggml/hip_backend/ops/q4_0_dequant.rs</files>
  <action>
Add GPU kernel cache initialization following the pattern from quantized_matmul.rs:

IMPORTANT: The existing `dequantize_q4_0_gpu()` function (lines 39-95) is a CPU fallback that uploads dequantized FP32 to GPU. Do NOT modify it directly. Instead, create a new kernel-based function.

1. Rename the existing `dequantize_q4_0_gpu()` to `dequantize_q4_0_cpu_upload()` to clarify it's CPU-side dequant with GPU upload (preserved as fallback).

2. Create `Q4_0DequantCache` struct with `module: Option<HipModule>` and `kernel: Option<HipKernel>`

3. Create `static Q4_0_DEQUANT_CACHE: Mutex<Option<Q4_0DequantCache>>`

4. Implement `get_or_init_q4_0_dequant_cache()` that:
   - Loads kernel path from `Q4_0_DEQUANT_HSACO` env var (set by build.rs)
   - Checks HSACO file exists before loading
   - Calls `backend.load_module()` and `backend.get_kernel_function(module, "q4_0_to_fp32_kernel")`
   - Returns error if env var not set or file not found (graceful degradation)

5. Implement NEW function `dequantize_q4_0_kernel_cached()` that:
   - Takes: backend, quantized_data (&[u8]), output (&HipBuffer), num_elements (usize)
   - Uploads quantized data to GPU buffer
   - Calculates grid dims: block_size=256, grid_size=(num_elements/32 + 255)/256
   - Launches kernel with args: input_ptr, output_ptr, num_blocks
   - Calls `backend.synchronize()` for completion
   - Returns Result<(), HipError>

6. Create public wrapper `dequantize_q4_0_with_fallback()` that:
   - Calls `dequantize_q4_0_kernel_cached()` first
   - On failure, falls back to `dequantize_q4_0_cpu_upload()`
   - Returns Result<(), String>

Pattern reference: src/ggml/hip_backend/ops/quantized_matmul.rs lines 101-148 for cache init pattern.
  </action>
  <verify>
cargo check --features rocm 2>&1 | head -50
# Verify kernel cache struct and function compile
grep -n "struct.*DequantCache\|get_or_init_q4_0_dequant_cache\|dequantize_q4_0_kernel_cached\|dequantize_q4_0_with_fallback" src/ggml/hip_backend/ops/q4_0_dequant.rs
# Verify fallback function renamed
grep -n "dequantize_q4_0_cpu_upload\|dequantize_q4_0_with_fallback" src/ggml/hip_backend/ops/q4_0_dequant.rs
  </verify>
  <done>
Q4_0 kernel cache struct exists, get_or_init_q4_0_dequant_cache() loads from Q4_0_DEQUANT_HSACO, dequantize_q4_0_kernel_cached() launches HIP kernel, dequantize_q4_0_with_fallback() provides graceful degradation to CPU upload.
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire Q4_0 GPU dequantization into GgufLoader</name>
  <files>src/loader/gguf.rs</files>
  <action>
Modify `load_tensor_to_gpu()` to use GPU dequantization for Q4_0:

1. Import GPU dequant function: `use crate::ggml::hip_backend::ops::q4_0_dequant::dequantize_q4_0_with_fallback;`

2. In the Q4_0 match arm (around line 744), replace the CPU dequantization path:
   - Current: Creates temp GgufTensor, calls `self.dequantize_q4_0()` (CPU), uploads FP32
   - New: Call `dequantize_q4_0_with_fallback(backend, tensor_bytes, &output_buffer, num_elements)`
   - The wrapper function handles GPU kernel with CPU fallback internally

3. The GPU path should:
   - Allocate output buffer with `backend.allocate_buffer(num_elements * 4)`
   - Call GPU dequant wrapper with quantized bytes directly
   - Synchronize and wrap in DeviceTensor
   - Cache result in self.gpu_cache

4. Remove explicit CPU fallback code from loader - the wrapper handles it

Reference: The current CPU dequantization path at lines 744-753.
  </action>
  <verify>
# Verify Q4_0 arm calls GPU wrapper
grep -A 10 "GgufTensorType::Q4_0" src/loader/gguf.rs | grep -E "dequantize_q4_0_with_fallback"
# Verify import exists
grep "use crate::ggml.*q4_0_dequant::dequantize_q4_0_with_fallback" src/loader/gguf.rs
# Verify no explicit CPU fallback in loader for Q4_0
grep -A 15 "GgufTensorType::Q4_0" src/loader/gguf.rs | grep -v "dequantize_q4_0_with_fallback" | grep "self.dequantize"
# If no output above, CPU fallback is properly delegated to wrapper
  </verify>
  <done>
Q4_0 match arm calls dequantize_q4_0_with_fallback(), uploads quantized bytes directly, fallback handled by wrapper function.
  </done>
</task>

<task type="auto">
  <name>Task 3: Update mod.rs to export new Q4_0 dequant functions</name>
  <files>src/ggml/hip_backend/ops/mod.rs</files>
  <action>
Update src/ggml/hip_backend/ops/mod.rs to export the new Q4_0 dequantization functions:

Add public exports after the q4_0_dequant module declaration:
```rust
pub use q4_0_dequant::{dequantize_q4_0_with_fallback, dequantize_q4_0_kernel_cached, get_or_init_q4_0_dequant_cache};
```

This allows external modules (like gguf.rs) to import and use the GPU dequantization functions.

Note: The q4_0_dequant module is already declared (line 11), just need to add the exports.
  </action>
  <verify>
# Verify exports exist
grep -n "pub use q4_0_dequant::" src/ggml/hip_backend/ops/mod.rs
# Verify specific functions exported
grep "dequantize_q4_0_with_fallback\|dequantize_q4_0_kernel_cached" src/ggml/hip_backend/ops/mod.rs
  </verify>
  <done>
mod.rs exports dequantize_q4_0_with_fallback, dequantize_q4_0_kernel_cached, and get_or_init_q4_0_dequant_cache for external use.
  </done>
</task>

<task type="auto">
  <name>Task 4: Add automated bit-exact GPU dequant unit tests (QUANT-05)</name>
  <files>tests/q_dequant_tests.rs</files>
  <action>
Add automated unit tests for GPU dequantization that verify bit-exact outputs (QUANT-05 requirement).

IMPORTANT: The test file may already exist. First check:
```bash
test -f tests/q_dequant_tests.rs && echo "File exists" || echo "File does not exist"
```

If file exists, append to it. If not, create new file.

Create/modify `tests/q_dequant_tests.rs` with the following test:

```rust
//! GPU Quantization Dequantization Unit Tests
//!
//! QUANT-05: Quantization kernels have unit tests verifying bit-exact outputs

use rocmforge::ggml::hip_backend::ops::q4_0_dequant::{
    dequantize_q4_0_kernel_cached, dequantize_q4_0_cpu
};
use rocmforge::backend::HipBackend;

#[test]
#[cfg(feature = "rocm")]
fn test_gpu_q4_0_bit_exact() {
    // This test runs in CI (no #[ignore]) and verifies bit-exact GPU output
    // It will be skipped if GPU is not available via runtime check, not #[ignore]

    let backend = match HipBackend::new() {
        Ok(b) => b,
        Err(_) => {
            println!("GPU not available - skipping test (not a failure)");
            return;
        }
    };

    // Create test data: 1 block with scale=1.0, values 0-15
    let mut data = vec![0u8; 20];
    data[0..4].copy_from_slice(&1.0f32.to_le_bytes());
    for i in 0..16 {
        data[4 + i] = ((i + 1) << 4) | i;
    }

    // CPU reference
    let cpu_result = dequantize_q4_0_cpu(&data, 32);

    // GPU result
    let output = backend.allocate_buffer(32 * 4).expect("Failed to allocate");
    dequantize_q4_0_kernel_cached(&backend, &data, &output, 32)
        .expect("GPU dequant failed");
    backend.synchronize().expect("Sync failed");

    let mut gpu_result = vec![0.0f32; 32];
    output.copy_to_host(&mut gpu_result).expect("Copy to host failed");

    // Verify bit-exact match (tolerance 0.001 allows for minimal FP rounding)
    for i in 0..32 {
        let diff = (cpu_result[i] - gpu_result[i]).abs();
        assert!(diff < 0.001,
            "Mismatch at {}: CPU={}, GPU={}, diff={}",
            i, cpu_result[i], gpu_result[i], diff);
    }
}
```

Key difference from `#[ignore]` tests:
- Uses runtime check (HipBackend::new()) instead of #[ignore]
- Returns early if GPU unavailable (not a test failure)
- Runs in CI when GPU is available
- Verifies bit-exact outputs with tight tolerance (0.001)

Pattern reference: Phase 15 GPU sampling tests for CI-friendly GPU test pattern.
  </action>
  <verify>
# Verify file exists and contains the automated test
grep -n "test_gpu_q4_0_bit_exact\|QUANT-05" tests/q_dequant_tests.rs
# Verify test is NOT marked #[ignore]
grep "test_gpu_q4_0_bit_exact" tests/q_dequant_tests.rs | grep -v "ignore"
# Verify test compiles
cargo test --features rocm test_gpu_q4_0_bit_exact 2>&1 | head -30
  </verify>
  <done>
tests/q_dequant_tests.rs exists with test_gpu_q4_0_bit_exact() that runs in CI (not #[ignore]), verifies bit-exact GPU output against CPU reference with tight tolerance.
  </done>
</task>

</tasks>

<verification>
1. cargo check passes with rocm feature
2. Q4_0_DEQUANT_HSACO env var is referenced in kernel cache initialization
3. load_tensor_to_gpu() Q4_0 arm calls GPU dequant wrapper function
4. Fallback to CPU upload is preserved via wrapper function
5. Automated unit test exists for GPU kernel correctness (QUANT-05 satisfied)
6. mod.rs exports new functions for external use
</verification>

<success_criteria>
1. Q4_0 weights are uploaded as quantized bytes (not FP32)
2. GPU kernel is invoked for dequantization (no CPU round-trip in happy path)
3. CPU fallback still works when GPU unavailable (graceful degradation via wrapper)
4. Automated unit test validates GPU dequantization produces bit-exact results (QUANT-05)
5. Code compiles without new warnings
6. Public API is cleanly exported via mod.rs
</success_criteria>

<output>
After completion, create `.planning/phases/17-gpu-quantization/17-01-SUMMARY.md`
</output>

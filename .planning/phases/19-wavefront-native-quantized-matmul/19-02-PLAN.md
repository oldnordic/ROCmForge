---
phase: 19-wavefront-native-quantized-matmul
plan: 02
type: execute
wave: 2
depends_on: ["19-01"]
files_modified: ["kernels/q4_0_matmul.hip", "kernels/q4_k_matmul.hip", "kernels/q6_k_matmul.hip"]
autonomous: true

must_haves:
  truths:
    - "All __shfl_down_f32 intrinsics replaced with HIP __shfl_down"
    - "WARP_SIZE constant corrected from 32 to 64 for RDNA3 wavefront alignment"
    - "Shared memory arrays resized from WARP_SIZE=32 to WARP_SIZE=64"
    - "No CUDA-specific intrinsics remain in quantized matmul kernels"
  artifacts:
    - path: "kernels/q4_0_matmul.hip"
      provides: "Q4_0 fused dequant+matmul with HIP wave reduction"
      min_lines: 400
      contains: "__shfl_down\\(partial, stride\\)"
      not_contains: "__shfl_down_f32|WARP_SIZE.*32|s_partial\\s*\\[\\s*32\\s*\\]"
    - path: "kernels/q4_k_matmul.hip"
      provides: "Q4_K fused dequant+matmul with HIP wave reduction"
      min_lines: 400
      contains: "__shfl_down\\(partial, stride\\)"
      not_contains: "__shfl_down_f32|WARP_SIZE.*32|s_partial\\s*\\[\\s*32\\s*\\]"
    - path: "kernels/q6_k_matmul.hip"
      provides: "Q6_K fused dequant+matmul with HIP wave reduction"
      min_lines: 400
      contains: "__shfl_down\\(partial, stride\\)"
      not_contains: "__shfl_down_f32|WARP_SIZE.*32|s_partial\\s*\\[\\s*32\\s*\\]"
  key_links:
    - from: "kernels/*.hip"
      to: "__builtin_amdgcn_wave_reduce_fadd"
      via: "Primary wave reduction path (already HIP-native)"
      pattern: "__builtin_amdgcn_wave_reduce_fadd"
    - from: "wave_reduce_sum fallback"
      to: "__shfl_down"
      via: "Fallback reduction now uses HIP __shfl_down without WARP_SIZE parameter"
      pattern: "__shfl_down\\(partial, stride\\)"
    - from: "WARP_SIZE constant"
      to: "64"
      via: "RDNA3 wavefront size is 64, not CUDA warp 32"
      pattern: "WARP_SIZE\\s+64"
---

<objective>
Replace CUDA __shfl_down_f32 intrinsics with HIP-native __shfl_down and correct WARP_SIZE from 32 to 64 for RDNA3 wavefront alignment in quantized matmul kernels (Q4_0, Q4_K, Q6_K).

Purpose: Remove all CUDA-specific code from quantized matmul kernels. The kernels already have a primary path using __builtin_amdgcn_wave_reduce_fadd (HIP-native), but the fallback path uses __shfl_down_f32 (CUDA). Additionally, WARP_SIZE is incorrectly set to 32 (CUDA warp) instead of 64 (RDNA3 wavefront), causing shared memory arrays to be undersized.

Output: Three HIP-native quantized matmul kernels with correct wave64 alignment that compile without CUDA intrinsic errors.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/phases/19-wavefront-native-quantized-matmul/19-RESEARCH.md
@.planning/research/ANTI_CUDA_PORTING_RATIONALE.md
@.planning/phases/19-wavefront-native-quantized-matmul/19-01-SUMMARY.md

@kernels/q4_0_matmul.hip
@kernels/q4_k_matmul.hip
@kernels/q6_k_matmul.hip
@/home/feanor/Projects/rocm-examples/HIP-Basic/warp_shuffle/main.hip
</context>

<tasks>

<task type="auto">
  <name>Task 1: Correct WARP_SIZE constant from 32 to 64</name>
  <files>kernels/q4_0_matmul.hip, kernels/q4_k_matmul.hip, kernels/q6_k_matmul.hip</files>
  <action>
    In all three quantized matmul kernels (q4_0_matmul.hip, q4_k_matmul.hip, q6_k_matmul.hip):

    1. Find the WARP_SIZE constant definition (typically: constexpr int WARP_SIZE = 32;)
    2. Change from: constexpr int WARP_SIZE = 32;
       Change to:   constexpr int WARP_SIZE = 64;

    Rationale: RDNA3 has 64 threads per wavefront (not 32 like CUDA warps). This affects:
    - Shared memory allocation (s_partial[WARP_SIZE])
    - Loop bounds in wave reduction
    - Wave barrier synchronization

    Search pattern: grep -n "WARP_SIZE" kernels/q4_0_matmul.hip
    Expected: Find definition near top of file, typically in global constants section.

    DO NOT change other constants named TILE_SIZE_K, TILE_SIZE_N (those are addressed in separate task).
    DO NOT change wavefront reduction logic itself (only the constant value).
  </action>
  <verify>
    grep -n "WARP_SIZE" /home/feanor/Projects/ROCmForge/kernels/q4_0_matmul.hip | grep -E "64|WARP_SIZE"
    grep -n "WARP_SIZE" /home/feanor/Projects/ROCmForge/kernels/q4_k_matmul.hip | grep -E "64|WARP_SIZE"
    grep -n "WARP_SIZE" /home/feanor/Projects/ROCmForge/kernels/q6_k_matmul.hip | grep -E "64|WARP_SIZE"
    # Expected: All show WARP_SIZE 64 (not 32)
  </verify>
  <done>
    WARP_SIZE corrected to 64 in all three matmul kernels (q4_0_matmul.hip, q4_k_matmul.hip, q6_k_matmul.hip)
  </done>
</task>

<task type="auto">
  <name>Task 2: Resize shared memory arrays for wave64 alignment</name>
  <files>kernels/q4_0_matmul.hip, kernels/q4_k_matmul.hip, kernels/q6_k_matmul.hip</files>
  <action>
    In all three quantized matmul kernels, find shared memory arrays sized with WARP_SIZE:

    Search pattern: grep -n "s_partial\[WARP_SIZE\]" kernels/*.hip

    Typical pattern: __shared__ float s_partial[WARP_SIZE];

    These arrays are used for wave reduction and MUST be sized for 64 elements (RDNA3 wavefront).
    After Task 1 corrected WARP_SIZE to 64, these arrays automatically resize.

    Verify no hardcoded [32] array sizes remain:
    - Search: s_partial[32]
    - Search: s_sum[32]
    - Any shared array with literal [32] size used for wave reduction

    If found, replace [32] with [WARP_SIZE] to use the corrected constant.
  </action>
  <verify>
    grep -n "s_partial\[" /home/feanor/Projects/ROCmForge/kernels/q4_0_matmul.hip /home/feanor/Projects/ROCmForge/kernels/q4_k_matmul.hip /home/feanor/Projects/ROCmForge/kernels/q6_k_matmul.hip | grep -v "\[WARP_SIZE\]" || echo "All arrays use WARP_SIZE constant"
    # Expected: Either arrays use [WARP_SIZE] or no matches with hardcoded sizes
  </verify>
  <done>
    All shared memory arrays use WARP_SIZE constant (now correctly 64), no hardcoded [32] sizes remain
  </done>
</task>

<task type="auto">
  <name>Task 3: Replace __shfl_down_f32 in q4_0_matmul.hip</name>
  <files>kernels/q4_0_matmul.hip</files>
  <action>
    In q4_0_matmul.hip, locate the wave_reduce_sum function (around lines 105-129).
    The fallback path (else branch) uses __shfl_down_f32.

    Replace line 115:
      partial += __shfl_down_f32(partial, stride, WARP_SIZE);
    With:
      partial += __shfl_down(partial, stride);

    Replace line 124:
      partial += __shfl_down_f32(partial, stride, WARP_SIZE);
    With:
      partial += __shfl_down(partial, stride);

    Key change: Remove _f32 suffix (HIP uses template-based overloading) and remove WARP_SIZE parameter (HIP infers from wavefront).

    DO NOT change the __builtin_amdgcn_wave_reduce_fadd path (already HIP-native).
    DO NOT import CUDA code or patterns.
  </action>
  <verify>
    grep -n "__shfl_down_f32" /home/feanor/Projects/ROCmForge/kernels/q4_0_matmul.hip || echo "PASS: No __shfl_down_f32 found"
    grep -n "__shfl_down(" /home/feanor/Projects/ROCmForge/kernels/q4_0_matmul.hip | grep -v "WARP_SIZE" || echo "PASS: __shfl_down calls have no WARP_SIZE parameter"
  </verify>
  <done>
    q4_0_matmul.hip: __shfl_down_f32 replaced with __shfl_down (2 occurrences), WARP_SIZE parameter removed
  </done>
</task>

<task type="auto">
  <name>Task 4: Replace __shfl_down_f32 in q4_k_matmul.hip</name>
  <files>kernels/q4_k_matmul.hip</files>
  <action>
    In q4_k_matmul.hip, locate the wave_reduce_sum function (around lines 168-190).
    The fallback path uses __shfl_down_f32.

    Replace line 176:
      partial += __shfl_down_f32(partial, stride, WARP_SIZE);
    With:
      partial += __shfl_down(partial, stride);

    Replace line 185:
      partial += __shfl_down_f32(partial, stride, WARP_SIZE);
    With:
      partial += __shfl_down(partial, stride);

    Same change pattern as q4_0_matmul.hip: remove _f32 suffix and WARP_SIZE parameter.

    DO NOT change the __builtin_amdgcn_wave_reduce_fadd path.
    DO NOT import CUDA code or patterns.
  </action>
  <verify>
    grep -n "__shfl_down_f32" /home/feanor/Projects/ROCmForge/kernels/q4_k_matmul.hip || echo "PASS: No __shfl_down_f32 found"
    grep -n "__shfl_down(" /home/feanor/Projects/ROCmForge/kernels/q4_k_matmul.hip | grep -v "WARP_SIZE" || echo "PASS: __shfl_down calls have no WARP_SIZE parameter"
  </verify>
  <done>
    q4_k_matmul.hip: __shfl_down_f32 replaced with __shfl_down (2 occurrences), WARP_SIZE parameter removed
  </done>
</task>

<task type="auto">
  <name>Task 5: Replace __shfl_down_f32 in q6_k_matmul.hip</name>
  <files>kernels/q6_k_matmul.hip</files>
  <action>
    In q6_k_matmul.hip, locate the wave_reduce_sum function (around lines 168-190).
    The fallback path uses __shfl_down_f32.

    Replace line 176:
      partial += __shfl_down_f32(partial, stride, WARP_SIZE);
    With:
      partial += __shfl_down(partial, stride);

    Replace line 185:
      partial += __shfl_down_f32(partial, stride, WARP_SIZE);
    With:
      partial += __shfl_down(partial, stride);

    Same change pattern as q4_0_matmul.hip and q4_k_matmul.hip.

    DO NOT change the __builtin_amdgcn_wave_reduce_fadd path.
    DO NOT import CUDA code or patterns.
  </action>
  <verify>
    grep -n "__shfl_down_f32" /home/feanor/Projects/ROCmForge/kernels/q6_k_matmul.hip || echo "PASS: No __shfl_down_f32 found"
    grep -n "__shfl_down(" /home/feanor/Projects/ROCmForge/kernels/q6_k_matmul.hip | grep -v "WARP_SIZE" || echo "PASS: __shfl_down calls have no WARP_SIZE parameter"
  </verify>
  <done>
    q6_k_matmul.hip: __shfl_down_f32 replaced with __shfl_down (2 occurrences), WARP_SIZE parameter removed
  </done>
</task>

<task type="auto">
  <name>Task 6: Verify tile sizes are wave64-aligned</name>
  <files>kernels/q4_0_matmul.hip, kernels/q4_k_matmul.hip, kernels/q6_k_matmul.hip</files>
  <action>
    Per ANTI_CUDA_PORTING_RATIONALE.md: "Tile sizes divisible by 64 | Wavefront alignment"

    Check TILE_SIZE_K and TILE_SIZE_N constants in all three kernels:
    grep -n "TILE_SIZE_[KN]" kernels/q4_0_matmul.hip kernels/q4_k_matmul.hip kernels/q6_k_matmul.hip

    Expected: Tile sizes should be divisible by 64 for wave64 alignment.
    - TILE_SIZE_K=64 or 128 (good)
    - TILE_SIZE_N=64 or 128 (good)
    - TILE_SIZE_K=32 or TILE_SIZE_N=32 (NOT wave64-aligned)

    If any tile size is not divisible by 64, document this as a known issue for 19-02-SUMMARY.md.
    DO NOT change tile sizes in this task (tile size changes require performance validation).
  </action>
  <verify>
    grep -n "TILE_SIZE_[KN].*[0-9]" /home/feanor/Projects/ROCmForge/kernels/q4_0_matmul.hip /home/feanor/Projects/ROCmForge/kernels/q4_k_matmul.hip /home/feanor/Projects/ROCmForge/kernels/q6_k_matmul.hip
  </verify>
  <done>
    Tile size alignment documented: TILE_SIZE_K and TILE_SIZE_N values recorded in 19-02-SUMMARY.md with wave64 alignment status
  </done>
</task>

</tasks>

<verification>
- grep returns "PASS: No __shfl_down_f32 found" for all three kernel files
- All three kernels now use __shfl_down (HIP-native) in fallback paths WITHOUT WARP_SIZE parameter
- WARP_SIZE verified as 64 (not 32) in all three kernels
- Shared memory arrays sized correctly for wave64
- Tile size alignment status documented
- __builtin_amdgcn_wave_reduce_fadd paths unchanged (already HIP-native)
</verification>

<success_criteria>
- WARP_SIZE constant corrected from 32 to 64 in all three matmul kernels
- Zero __shfl_down_f32 occurrences remain in q4_0_matmul.hip, q4_k_matmul.hip, q6_k_matmul.hip
- All __shfl_down calls have 2 parameters (partial, stride), NOT 3 parameters (no WARP_SIZE)
- Shared memory arrays use WARP_SIZE=64 for proper allocation
- Tile size alignment documented (known issues if any)
- Primary paths continue using __builtin_amdgcn_wave_reduce_fadd (unchanged)
</success_criteria>

<output>
After completion, create `.planning/phases/19-wavefront-native-quantized-matmul/19-02-SUMMARY.md` with WARP_SIZE correction, intrinsic replacements, and tile size alignment status.
</output>

---
phase: 05-quantized-operations
plan: 01
type: execute
depends_on: []
files_modified: [.planning/phases/05-quantized-operations/RESEARCH.md]
autonomous: true
---

<objective>
Research and document quantization formats and dequantization algorithms for GGUF models.

Purpose: Establish technical foundation for implementing HIP dequantization kernels. Understand Q-format specifications, dequantization algorithms, and HIP kernel patterns.
Output: Research documentation (RESEARCH.md) with format specifications and implementation strategy.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@src/loader/dequant.rs
@src/loader/tensor_type.rs
@src/ggml/hip_backend/ops/quantized_matmul.rs
@kernels/mxfp_dequant.hip
@build.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Document Q-format specifications</name>
  <files>.planning/phases/05-quantized-operations/RESEARCH.md</files>
  <action>
    Create RESEARCH.md documenting all Q-format specifications found in GGUF:

    For each format (Q4_0, Q4_1, Q5_0, Q5_1, Q8_0, Q4_K, Q6_K), document:
    - Block size (elements per block)
    - Block structure (scale bytes, quantized data bytes)
    - Dequantization formula (how to convert to FP32)
    - Bit packing details (how values are packed into bytes)
    - Data layout in memory

    Use existing src/loader/dequant.rs as reference - it has correct implementations.

    Include reference tables for:
    - Format comparison (bits per element, compression ratio, block size)
    - Block structure diagrams
  </action>
  <verify>RESEARCH.md created with all format specifications</verify>
  <done>All Q-format specifications documented</done>
</task>

<task type="auto">
  <name>Task 2: Analyze existing CPU dequantization code</name>
  <files>.planning/phases/05-quantized-operations/RESEARCH.md</files>
  <action>
    Analyze src/loader/dequant.rs to extract proven dequantization algorithms:

    Document each function's approach:
    - Q4_0: 4-bit packed, scale-based dequantization
    - Q4_1: 4-bit packed with min value
    - Q5_0: 5-bit (4-bit packed + high bit in qh)
    - Q5_1: 5-bit with min value
    - Q8_0: 8-bit signed integer with scale
    - Q4_K: Super-block structure (256-byte blocks, 8 sub-blocks)
    - Q6_K: 6-bit packed, half-precision scales

    Note:
    - Rayon parallelization (for CPU implementation)
    - Error handling patterns
    - Memory access patterns
  </action>
  <verify>CPU dequantization patterns documented in RESEARCH.md</verify>
  <done>Existing CPU algorithms analyzed and documented</done>
</task>

<task type="auto">
  <name>Task 3: Document HIP kernel patterns from mxfp_dequant.hip</name>
  <files>.planning/phases/05-quantized-operations/RESEARCH.md</files>
  <action>
    Analyze kernels/mxfp_dequant.hip to establish HIP kernel patterns:

    Document:
    - Kernel launch pattern (grid/block sizing)
    - Device function patterns (decode_e2m1, decode_e2m3)
    - Memory access patterns (coalesced reads, shared memory usage)
    - Block-level parallelism (one block per quantized block)
    - RDNA3 tuning constants (BLOCK_SIZE=256, WARP_SIZE=32)

    Extract reusable patterns for Q-format kernels:
    - Bit unpacking functions
    - Scale application
    - Boundary checking
  </action>
  <verify>HIP kernel patterns documented in RESEARCH.md</verify>
  <done>Kernel patterns extracted for reuse in Q-format kernels</done>
</task>

<task type="auto">
  <name>Task 4: Design Q-format kernel implementation strategy</name>
  <files>.planning/phases/05-quantized-operations/RESEARCH.md</files>
  <action>
    Design implementation strategy for Q-format HIP kernels:

    Priority order (by model usage):
    1. Q4_0 - Most common format for weights
    2. Q8_0 - Used for activations
    3. Q4_K, Q6_K - Modern K-quants (better quality)
    4. Q5_0, Q5_1 - Less common

    Kernel design per format:
    - Input: Packed quantized data (uint8_t*)
    - Output: FP32 values (float*)
    - Block layout: Match Q-format block size (32 for Q4/Q5/Q8, 256 for Q_K)
    - Thread assignment: One thread per element in block
    - Bit unpacking: Follow format-specific patterns

    Build system integration:
    - Add kernel source files to kernels/ directory
    - Add entry to build.rs kernels array
    - Add env var for HSACO path
    - Create Rust wrapper functions in src/ggml/hip_backend/ops/
  </action>
  <verify>Implementation strategy documented in RESEARCH.md</verify>
  <done>Kernel design and build integration strategy defined</done>
</task>

</tasks>

<verification>
- [ ] RESEARCH.md created with format specifications
- [ ] CPU dequantization patterns analyzed
- [ ] HIP kernel patterns extracted
- [ ] Implementation strategy defined
</verification>

<success_criteria>
- Comprehensive understanding of all Q-format specifications
- Clear path from CPU implementation to HIP kernel implementation
- Reusable patterns established for Q-format kernel development
- Build system integration approach documented
</success_criteria>

<output>
After completion, create `.planning/phases/05-quantized-operations/05-01-SUMMARY.md`
</output>

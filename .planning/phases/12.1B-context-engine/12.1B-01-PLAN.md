---
phase: 12.1B-context-engine
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - Cargo.toml
  - src/context/graph_context.rs
  - src/context/hnsw_index.rs
  - src/lib.rs
  - src/engine.rs
autonomous: true
user_setup:
  - service: sqlitegraph
    why: "LLM context augmentation with HNSW vector search"
    env_vars:
      - name: SQLITEGRAPH_PATH
        source: "Optional: path to persistent graph database (defaults to in-memory)"
    dashboard_config: []

must_haves:
  truths:
    - "Messages can be added to graph context store with embeddings"
    - "HNSW index enables semantic search by query embedding"
    - "Graph edges connect messages in conversation sequence"
    - "Context retrieval finds relevant messages by vector similarity"
    - "HTTP endpoint /v1/context/search exposed for context queries"
  artifacts:
    - path: "src/context/graph_context.rs"
      provides: "Graph-based context storage and retrieval"
      exports: ["GraphContextStore", "add_message", "retrieve_context", "search"]
      min_lines: 150
    - path: "src/context/hnsw_index.rs"
      provides: "HNSW vector index wrapper for message embeddings"
      exports: ["HnswIndex", "insert_embedding", "search"]
      min_lines: 100
    - path: "src/http/handlers.rs"
      provides: "HTTP endpoint for context search"
      contains: "async fn context_search"
  key_links:
    - from: "src/context/graph_context.rs"
      to: "sqlitegraph"
      via: "SqliteGraph and HnswIndex from sqlitegraph crate"
      pattern: "sqlitegraph::|sqlitegraph::hnsw::"
    - from: "src/engine.rs"
      to: "src/context/graph_context.rs"
      via: "GraphContextStore added to Engine struct"
      pattern: "context_store:.*GraphContextStore"
    - from: "src/http/handlers.rs"
      to: "src/context/graph_context.rs"
      via: "Context search handler calls store.retrieve_context()"
      pattern: "context_store.*retrieve_context"
---

<objective>
SQLiteGraph Context Integration for LLM Augmentation

Purpose: Integrate SQLiteGraph for semantic context storage and retrieval, enabling extended LLM context windows (20k -> 200k "pseudo-context") through HNSW vector search and graph-based message relationships.

Output: GraphContextStore module with HNSW indexing, HTTP API for context search, CLI commands for context management.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/phases/12-complete-cpu-simd-attention/12.1-RESEARCH.md
@/home/feanor/Projects/sqlitegraph/API.md
@src/engine.rs
@src/http/handlers.rs
@Cargo.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add sqlitegraph dependency and create context module</name>
  <files>src/context/mod.rs, src/context/graph_context.rs, Cargo.toml</files>
  <action>
    Create context infrastructure:

    1. Add to Cargo.toml dependencies:
       ```toml
       [dependencies]
       sqlitegraph = { version = "1.0", optional = true }
       ```

    2. Add feature flag:
       ```toml
       [features]
       default = []
       context = ["sqlitegraph"]
       ```

    3. Create src/context/mod.rs:
       ```rust
       #[cfg(feature = "context")]
       pub mod graph_context;

       #[cfg(feature = "context")]
       pub use graph_context::{GraphContextStore, ContextMessage};
       ```

    4. Create src/context/graph_context.rs with types:
       ```rust
       use sqlitegraph::{SqliteGraph, GraphEntity, GraphEdge};
       use sqlitegraph::hnsw::{HnswIndex, HnswConfig, DistanceMetric};

       #[derive(Debug, Clone)]
       pub struct ContextMessage {
           pub id: u64,
           pub text: String,
           pub embedding: Vec<f32>,
           pub timestamp: i64,
           pub seq_id: usize,
       }

       pub struct GraphContextStore {
           graph: SqliteGraph,
           hnsw: HnswIndex,
           dimension: usize,
       }
       ```

    5. Implement GraphContextStore::new():
       - Creates in-memory SqliteGraph
       - Creates HnswIndex with cosine distance (for text embeddings)
       - Accepts embedding dimension (typically 384 for MiniLM, 1536 for OpenAI)

    6. Add to src/lib.rs:
       ```rust
       #[cfg(feature = "context")]
       pub mod context;
       ```
  </action>
  <verify>cargo check --features context 2>&1 | grep -E "(error|warning|Compiling)" | head -10</verify>
  <done>
    - sqlitegraph dependency compiles
    - context module compiles with feature flag
    - GraphContextStore::new() creates graph and HNSW index
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement message storage with HNSW indexing</name>
  <files>src/context/graph_context.rs</files>
  <action>
    Implement add_message and embedding pipeline:

    1. Add EmbeddingModel trait (placeholder for now):
       ```rust
       pub trait EmbeddingModel: Send + Sync {
           fn embed(&self, text: &str) -> Result<Vec<f32>, anyhow::Error>;
           fn dimension(&self) -> usize;
       }

       // Placeholder implementation using dummy embeddings
       // Real implementation would call OpenAI API or local model
       pub struct DummyEmbedding {
           pub dimension: usize,
       }
       ```

    2. Implement GraphContextStore::add_message():
       ```rust
       pub fn add_message(
           &mut self,
           text: &str,
           seq_id: usize,
           prev_id: Option<u64>,
       ) -> Result<u64, anyhow::Error> {
           // 1. Generate embedding
           let embedding = self.embedding_model.embed(text)?;

           // 2. Create graph entity
           let entity = GraphEntity {
               id: 0,
               kind: "message".to_string(),
               name: format!("msg_{}", seq_id),
               file_path: None,
               data: json!({
                   "text": text,
                   "timestamp": Utc::now().to_rfc3339(),
                   "seq_id": seq_id,
               }),
           };
           let node_id = self.graph.insert_entity(&entity)?;

           // 3. Insert into HNSW
           self.hnsw.insert_vector(&embedding, Some(json!({"node_id": node_id})))?;

           // 4. Create edge to previous message
           if let Some(prev) = prev_id {
               let edge = GraphEdge {
                   id: 0,
                   from_id: prev,
                   to_id: node_id,
                   edge_type: "follows".to_string(),
                   data: json!({}),
               };
               self.graph.insert_edge(&edge)?;
           }

           Ok(node_id)
       }
       ```

    3. Store message_id -> embedding mapping for retrieval

    4. Tests:
       - Add multiple messages, verify HNSW size
       - Verify edges connect in sequence
  </action>
  <verify>cargo test --package rocmforge --lib context::add_message 2>&1 | grep -E "(test|PASS|FAIL)"</verify>
  <done>
    - add_message() creates graph node and HNSW entry
    - Messages connected via "follows" edges
    - HNSW index contains embeddings for all messages
  </done>
</task>

<task type="auto">
  <name>Task 3: Implement semantic context retrieval</name>
  <files>src/context/graph_context.rs</files>
  <action>
    Implement retrieval functions:

    1. Add retrieve_context():
       ```rust
       pub fn retrieve_context(
           &self,
           query: &str,
           k: usize,
       ) -> Result<Vec<ContextMessage>, anyhow::Error> {
           // 1. Embed query
           let query_emb = self.embedding_model.embed(query)?;

           // 2. HNSW search
           let results = self.hnsw.search(&query_emb, k)?;

           // 3. Fetch message entities by node_id
           let mut messages = Vec::new();
           for result in results {
               if let Some(node_id) = result.metadata.get("node_id") {
                   let id = node_id.as_u64().unwrap();
                   let entity = self.graph.get_entity(id)?;
                   messages.push(ContextMessage {
                       id: entity.id,
                       text: entity.data["text"].as_str().unwrap().to_string(),
                       // ... other fields
                   });
               }
           }

           Ok(messages)
       }
       ```

    2. Add graph expansion (optional, for context breadth):
       ```rust
       pub fn retrieve_context_expanded(
           &self,
           query: &str,
           k: usize,
           expand_neighbors: bool,
       ) -> Result<Vec<ContextMessage>, anyhow::Error> {
           // After HNSW search, expand to neighbors
           // This gives conversation continuity
       }
       ```

    3. Tests:
       - Add messages, query finds semantically similar
       - Verify results ordered by similarity score
  </action>
  <verify>cargo test --package rocmforge --lib context::retrieve 2>&1 | grep -E "(test|PASS|FAIL)"</verify>
  <done>
    - retrieve_context() returns k most similar messages
    - Results ordered by similarity score
    - Expansion includes neighbor messages
  </done>
</task>

<task type="auto">
  <name>Task 4: Add HTTP endpoint and CLI integration</name>
  <files>src/http/handlers.rs, src/cli/commands.rs, src/engine.rs</files>
  <action>
    Expose context via API and CLI:

    1. Add to src/http/handlers.rs:
       ```rust
       use crate::context::GraphContextStore;

       pub async fn context_search(
       State(store): State<Arc<GraphContextStore>>,
       Query(params): Query<ContextSearchParams>,
       ) -> Result<Json<Vec<ContextMessage>>, AppError> {
           let messages = store.retrieve_context(&params.q, params.k.unwrap_or(5))?;
           Ok(Json(messages))
       }
       ```

    2. Add router in src/http/main.rs (or appropriate router file):
       ```rust
       #[cfg(feature = "context")]
       app.route("/v1/context/search", get(context_search))
       ```

    3. Add CLI commands in src/cli/commands.rs:
       ```rust
       #[cfg(feature = "context")]
       pub struct ContextCommand {
           pub db_path: Option<String>,
           pub subcommand: ContextSubcommand,
       }

       pub enum ContextSubcommand {
           Add { text: String },
           Search { query: String, k: Option<usize> },
           Export { output: String },
       }
       ```

    4. Integrate GraphContextStore into Engine (optional, for context-aware inference):
       ```rust
       // src/engine.rs
       #[cfg(feature = "context")]
       pub struct Engine {
           // ... existing fields
           pub context_store: Option<Arc<GraphContextStore>>,
       }
       ```

    5. Tests:
       - HTTP endpoint returns JSON
       - CLI add/search commands work
  </action>
  <verify>cargo test --package rocmforge --lib http::context 2>&1 | grep -E "(test|PASS|FAIL)"</verify>
  <done>
    - GET /v1/context/search?q=hello&k=5 returns similar messages
    - CLI `rocmforge context add "message"` works
    - CLI `rocmforge context search "query"` works
  </done>
</task>

</tasks>

<verification>
1. Unit tests for GraphContextStore operations
2. Integration test for HTTP endpoint
3. CLI manual test (documented in SUMMARY)
4. No clippy warnings
5. Cargo check --all-features passes
</verification>

<success_criteria>
- GraphContextStore implemented with HNSW search
- Messages stored as graph nodes with embeddings
- Semantic search returns relevant messages
- HTTP endpoint /v1/context/search functional
- CLI commands for context management
- Context feature gated behind "context" feature flag
- Dummy embeddings work; real embeddings documented for future
</success_criteria>

<output>
After completion, create `.planning/phases/12.1-cpu-simd-enhancements/12.1-03-SUMMARY.md`
</output>
